{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0cefcff4",
   "metadata": {},
   "source": [
    "# Modeling & Summary\n",
    "- 목적\n",
    "> - PUBG Finish Placement Prediction 대회 dataleakage로 인하여, 문제 'killplace'컬럼을 제외한 데이터들에 대해서 모델 성능 개선\n",
    "> - 기준이 되는 Base model(xgboost 0.090195,0.09180 mae 기준)을 제작하였으며 전처리 및 모델 학습을 통한 성능 개선하였습니다.\n",
    "- 1.Preprocessing\n",
    "> - 이상치 제거 DataFrame 불러온다.\n",
    "> - Groupid 기준으로 target값을 제외한 컬럼에 대해 평균값을 각 gropuid 기준으로 넣어준다.\n",
    ">> - pubg는 groupid 별로 target값이 생성되기 때문에 group의 전반적인 데이터를 고려할 수 있도록 평균치를 넣어주었습니다.\n",
    "> - Dataframe을 X,y으로 분리하여 모델학습을 진행한다.\n",
    "- 2. Model Test\n",
    "> - model select을 위해 6개의 regression 모델 성능 비교\n",
    "> - 상위 3개 모델 select\n",
    "- 3. Model Hyperparameter Tuning & Model ensemble\n",
    "> - select model Hyperparameter Tuning\n",
    "> - voting regression을 3개의 모델에 대해서 진행하였습니다.\n",
    "- 4. Conclusion\n",
    "> - 최종적으로 Base model(xgboost 0.090195,0.09180 mae 기준)보다 0.024정도 성능 개선하였습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2691ca",
   "metadata": {},
   "source": [
    "# 1. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c91f1d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "pd.set_option('display.max_columns', None)\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import Ridge\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import VotingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e212ce76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 경로설정\n",
    "df = pd.read_csv('../../data/train_preprocessed.csv')\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b33aae4",
   "metadata": {},
   "source": [
    "- 이상치 전처리한 DataFrame을 불러옵니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ceaf074",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineering(df):\n",
    "    #수치형 데이터\n",
    "    df_col= [ 'assists', 'boosts', 'damageDealt', 'DBNOs',\n",
    "       'headshotKills', 'heals', 'killPlace', 'killPoints', 'kills','matchType',\n",
    "       'killStreaks', 'longestKill', 'matchDuration', 'maxPlace',\n",
    "       'numGroups', 'rankPoints', 'revives', 'rideDistance', 'roadKills',\n",
    "       'swimDistance', 'teamKills', 'vehicleDestroys', 'walkDistance',\n",
    "       'weaponsAcquired', 'winPoints']\n",
    "    # df_t는 데이터를 그룹아이디 기준으로 평균을 내기 위해 저장할 데이터프레임\n",
    "    df_t=df.copy()\n",
    "    #라벨인코딩\n",
    "    le = LabelEncoder()\n",
    "    df_t['matchType']= le.fit_transform(df_t['matchType'])\n",
    "    df_t['matchType']\n",
    "    # 그룹아이디를 기준으로 수치형 컬럼들을 평균화\n",
    "    df_t= df_t.groupby(['groupId'])[df_col].agg('mean').reset_index()\n",
    "    \n",
    "    return df_t\n",
    "\n",
    "\n",
    "train02 = feature_engineering(df)\n",
    "\n",
    "train03=df[['groupId','winPlacePerc']]\n",
    "\n",
    "train03=pd.merge(train03,train02,how='left',on='groupId')\n",
    "train03=train03.drop(columns=['killPlace','groupId'])\n",
    "\n",
    "X=train03.drop(columns='winPlacePerc')\n",
    "y=train03[['winPlacePerc']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0cc73c6",
   "metadata": {},
   "source": [
    "- Groupid 기준으로 target값을 제외한 컬럼에 대해 평균값을 각 gropuid 기준으로 넣어줍니다.\n",
    "- 이를 통해 group 별로 동일한 컬럼 값을 가지게됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7b4e0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b38119a",
   "metadata": {},
   "source": [
    "- Dataframe을 train, valid로 분리합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ca79d5",
   "metadata": {},
   "source": [
    "# 2. Model Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "15d81dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델에 따른 학습 진행 함수\n",
    "def cal_mae(X, y, func):\n",
    "    \n",
    "    # 학습\n",
    "    model = func.fit(X, y)\n",
    "    \n",
    "    # 모델 평가\n",
    "    y_pred = model.predict(X_valid)\n",
    "    return mean_absolute_error(y_valid, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c3f08f9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tb/j9qmrzv54k73r5l100jxqll80000gn/T/ipykernel_5409/3713937285.py:5: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  model = func.fit(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regressor :  mae = 0.09922127415562758\n",
      "Lasso :  mae = 0.11740991483931458\n",
      "Ridge :  mae = 0.09922127466890124\n",
      "RandomForest :  mae = 0.008669915788687477\n",
      "XGBRegressor :  mae = 0.06774482224921537\n",
      "LGBMRegressor :  mae = 0.06908689886200906\n"
     ]
    }
   ],
   "source": [
    "# LinearRegression\n",
    "LR = cal_mae(X, y, LinearRegression())\n",
    "# Lasso\n",
    "LS = cal_mae(X, y, Lasso())\n",
    "# Ridge\n",
    "RG = cal_mae(X, y, Ridge())\n",
    "# RandomForest\n",
    "RDF = cal_mae(X, y, RandomForestRegressor(n_estimators=100,random_state=0, n_jobs= -1))\n",
    "# XGBRegressor\n",
    "XGBR = cal_mae(X, y, xgb.XGBRegressor(n_estimators=100, n_jobs= -1))\n",
    "# LGBMRegressor\n",
    "LGB = cal_mae(X, y, lgb.LGBMRegressor(n_estimators=100, n_jobs= -1))\n",
    "\n",
    "print(f'Linear Regressor :  mae = {LR}')\n",
    "print(f'Lasso :  mae = {LS}')\n",
    "print(f'Ridge :  mae = {RG}')\n",
    "print(f'RandomForest :  mae = {RDF}')\n",
    "print(f'XGBRegressor :  mae = {XGBR}')\n",
    "print(f'LGBMRegressor :  mae = {LGB}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9531ac",
   "metadata": {},
   "source": [
    "- LinearRegression, Lasso, Ridge, RandomForest, XGBRegressor, LGBMRegressor 총 6개 모델에 대해 성능 비교\n",
    "- RandomForest, XGBRegressor, LGBMRegressor 상위 3개 모델 select 하였습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5437418a",
   "metadata": {},
   "source": [
    "# 3. Model Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f825a22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost = xgb.XGBRegressor(\n",
    "    reg_lambda = 2.7806808012468585,\n",
    "    alpha = 0.011386465419313093,\n",
    "    colsample_bytree = 0.7,\n",
    "    subsample = 0.8,\n",
    "    learning_rate = 0.014,\n",
    "    n_estimators = 750,\n",
    "    max_depth = 11,\n",
    "    random_state = 42,\n",
    "    min_child_weight = 231,\n",
    "    n_jobs = -1\n",
    ")\n",
    "\n",
    "lightgbm = lgb.LGBMRegressor(\n",
    "    lambda_l1 = 0.00011127147165282962,\n",
    "    lambda_l2 = 4.381519364899678e-05,\n",
    "    path_smooth = 1.356576322384448e-07,\n",
    "    learning_rate = 0.05,\n",
    "    num_leaves = 138,\n",
    "    min_data_in_leaf = 55,\n",
    "    max_bin = 199,\n",
    "    n_estimators = 751,\n",
    "    feature_fraction = 0.5160178724035975,\n",
    "    bagging_fraction = 0.5257183949059583,\n",
    "    random_state = 42,\n",
    "    n_jobs= -1,\n",
    ")\n",
    "\n",
    "rf = RandomForestRegressor(\n",
    "    n_estimators = 355,\n",
    "    random_state = 42,\n",
    "    max_depth = 10,\n",
    "    min_samples_leaf = 5,\n",
    "    min_samples_split = 12\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf205ec6",
   "metadata": {},
   "source": [
    "- 각 모델별 하이퍼파라미터 튜닝을 진행하였으며 최적의 하이퍼파라미터 기준으로 모델을 생성하였습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9e3886d",
   "metadata": {},
   "outputs": [],
   "source": [
    "votingreg = VotingRegressor([('lightgbm', lightgbm), \n",
    "                             ('xgboost', xgboost),\n",
    "                             ('rf',rf)\n",
    "                            ],\n",
    "                           verbose=True,\n",
    "                            n_jobs=-1\n",
    "                           )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "479705ff",
   "metadata": {},
   "source": [
    "- 3개 모델에 대해 VotingRegressor 모델 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e6113c",
   "metadata": {},
   "source": [
    "# 4. Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6be8a06e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.5160178724035975, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5160178724035975\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5257183949059583, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5257183949059583\n",
      "[LightGBM] [Warning] lambda_l2 is set=4.381519364899678e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=4.381519364899678e-05\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=55, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=55\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.00011127147165282962, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00011127147165282962\n",
      "[Voting] ................. (1 of 3) Processing lightgbm, total= 4.1min\n",
      "MAE: 0.06697931354289616\n",
      "[Voting] ....................... (3 of 3) Processing rf, total=98.7min\n",
      "[Voting] .................. (2 of 3) Processing xgboost, total=98.8min\n"
     ]
    }
   ],
   "source": [
    "# votingreg.fit(X_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "676f9333",
   "metadata": {},
   "source": [
    "- voting regressor train 진행하였습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "325642ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.06697931354289616\n"
     ]
    }
   ],
   "source": [
    "preds = votingreg.predict(X_valid)\n",
    "print('MAE:', mean_absolute_error(y_valid, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6642f8d0",
   "metadata": {},
   "source": [
    "- VotingRegressor를 통해 최종 스코어 0.06697931354289616(mae) 입니다.\n",
    "- 최종적으로 Base model(xgboost 0.090195,0.09180 mae 기준)보다 0.024정도 성능 개선하였습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c93dee2f",
   "metadata": {},
   "source": [
    "# 모델 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "158e7c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# save\n",
    "# with open('model.pkl','wb') as f:\n",
    "#     pickle.dump(votingreg,f)\n",
    "\n",
    "# load\n",
    "with open('model.pkl', 'rb') as f:\n",
    "    clf = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "92280e2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00581821, 0.85296118, 0.86305033, ..., 0.8335614 , 0.1363089 ,\n",
       "       0.50674418])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d89e01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
