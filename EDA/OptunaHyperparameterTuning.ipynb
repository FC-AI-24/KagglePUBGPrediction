{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "568a5f88",
   "metadata": {},
   "source": [
    "# OPTUNA 이용한 하이퍼파라미터 튜닝\n",
    "- xgboost\n",
    "- ligthgbm\n",
    "- randomforest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b859e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from functools import partial\n",
    "import optuna\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ff9867",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 경로설정\n",
    "df = pd.read_csv('../../data/train_V2.csv')\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ecbb8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineering(df):\n",
    "    #수치형 데이터\n",
    "    df_col= [ 'assists', 'boosts', 'damageDealt', 'DBNOs',\n",
    "       'headshotKills', 'heals', 'killPlace', 'killPoints', 'kills','matchType',\n",
    "       'killStreaks', 'longestKill', 'matchDuration', 'maxPlace',\n",
    "       'numGroups', 'rankPoints', 'revives', 'rideDistance', 'roadKills',\n",
    "       'swimDistance', 'teamKills', 'vehicleDestroys', 'walkDistance',\n",
    "       'weaponsAcquired', 'winPoints']\n",
    "    # df_t는 데이터를 그룹아이디 기준으로 평균을 내기 위해 저장할 데이터프레임\n",
    "    df_t=df.copy()\n",
    "    #라벨인코딩\n",
    "    le = LabelEncoder()\n",
    "    df_t['matchType']= le.fit_transform(df_t['matchType'])\n",
    "    df_t['matchType']\n",
    "    # 그룹아이디를 기준으로 수치형 컬럼들을 평균화\n",
    "    df_t= df_t.groupby(['groupId'])[df_col].agg('mean').reset_index()\n",
    "    \n",
    "    return df_t\n",
    "\n",
    "\n",
    "# df에는 앞에서 만든 함수를 통해 피처 엔지니어링 수치형 데이터를 평균을 냄\n",
    "train02 = feature_engineering(df)\n",
    "\n",
    "#원본 train01 데이터의 순서와 로우를 잃지 않기 위해 그룹아이디와 그에 맞는 타겟벨류를 가지고옴\n",
    "train03=df[['groupId','winPlacePerc']]\n",
    "\n",
    "# 데이터 합치기- 앞에서 데이터를 피처 엔지니어링한 train02를 원본 데이터인 train03의 순서에 맞게 넣기 위해 merge를 사용.\n",
    "# how='left'는 두 데이터프레임중 기준을 잡을 데이터프레임을 정함.\n",
    "# 원본train03 의 순서와 로우수를 맞춰줌\n",
    "train03=pd.merge(train03,train02,how='left',on='groupId')\n",
    "# 모델 학습을 위해 두가지 변수를 제거 killplace는 큰 비중을 차지하여 공부를 위해 제거 groupId는 학습을 위해 수치형 데이터만\n",
    "#남게 하기 위해 제거 \n",
    "train03=train03.drop(columns=['killPlace','groupId'])\n",
    "\n",
    "X=train03.drop(columns='winPlacePerc')\n",
    "y=train03[['winPlacePerc']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da727d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimizer(trial, X, y, model):\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    if model == 'xgb':\n",
    "        param = {\n",
    "            'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
    "            'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
    "            'colsample_bytree': trial.suggest_categorical('colsample_bytree', [0.3,0.4,0.5,0.6,0.7,0.8,0.9, 1.0]),\n",
    "            'subsample': trial.suggest_categorical('subsample', [0.4,0.5,0.6,0.7,0.8,1.0]),\n",
    "            'learning_rate': trial.suggest_categorical('learning_rate', [0.01,0.014, 0.02, 0.05]),\n",
    "            'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n",
    "            'max_depth': trial.suggest_categorical('max_depth', [5,7,9,11,13,15,17]),\n",
    "            'random_state': trial.suggest_categorical('random_state', [42]),\n",
    "            'min_child_weight': trial.suggest_int('min_child_weight', 0, 300),\n",
    "            'n_jobs': -1\n",
    "        }\n",
    "        model = xgb.XGBRegressor(**param)\n",
    "        model.fit(X_train,y_train,eval_set=[(X_valid,y_valid)],early_stopping_rounds=200)\n",
    "        preds = model.predict(X_valid)\n",
    "    \n",
    "    elif model == 'lgb':\n",
    "        param = {\n",
    "            'lambda_l1' : trial.suggest_loguniform('lambda_l1', 1e-8, 1e-1),\n",
    "            'lambda_l2' : trial.suggest_loguniform('lambda_l2', 1e-8, 1e-1),\n",
    "            'path_smooth' : trial.suggest_loguniform('path_smooth', 1e-8, 1e-3),\n",
    "            'learning_rate': trial.suggest_categorical('learning_rate', [0.01,0.014, 0.02, 0.05]),\n",
    "            'num_leaves' : trial.suggest_int('num_leaves', 30, 200),\n",
    "            'min_data_in_leaf' : trial.suggest_int('min_data_in_leaf', 10, 100),\n",
    "            'max_bin' : trial.suggest_int('max_bin', 100, 255),\n",
    "            'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n",
    "            'feature_fraction' : trial.suggest_uniform('feature_fraction', 0.5, 0.9),\n",
    "            'bagging_fraction' : trial.suggest_uniform('bagging_fraction', 0.5, 0.9),\n",
    "            'random_state': trial.suggest_categorical('random_state', [42]),\n",
    "            'n_jobs': -1,\n",
    "        }\n",
    "        \n",
    "        model = lgb.LGBMRegressor(**param)\n",
    "        \n",
    "        model.fit(X_train, y_train,eval_set=[(X_valid, y_valid)],eval_metric='l1',early_stopping_rounds=200)\n",
    "        preds = model.predict(X_valid)\n",
    "\n",
    "    elif model == 'rf':\n",
    "        param = {\n",
    "            'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n",
    "            'random_state': trial.suggest_categorical('random_state', [42]),\n",
    "            'max_depth': trial.suggest_categorical('max_depth', [5,7,9,10]),\n",
    "            'min_samples_leaf': trial.suggest_categorical('min_samples_leaf', [3, 4, 5]),\n",
    "            'min_samples_split': trial.suggest_categorical('min_samples_split', [8, 10, 12]),\n",
    "            'n_jobs': -1,\n",
    "        }\n",
    "        \n",
    "        model = RandomForestRegressor(**param)\n",
    "        model.fit(X_train, y_train)\n",
    "        preds = model.predict(X_valid)\n",
    "        \n",
    "    mae = mean_absolute_error(y_valid, preds)\n",
    "    \n",
    "    return mae\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6b584c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgboost\n",
    "opt_func = partial(optimizer, X=X, y=y, model='xgb')\n",
    "\n",
    "xgb_study = optuna.create_study(direction=\"minimize\")\n",
    "xgb_study.optimize(opt_func, n_trials=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f9187b",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_study.trials_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60562152",
   "metadata": {},
   "outputs": [],
   "source": [
    "Best_trial = xgb_study.best_trial.params\n",
    "Best_trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156e41f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lightgbm\n",
    "opt_func = partial(optimizer, X=X, y=y, model='lgb')\n",
    "\n",
    "lgb_study = optuna.create_study(direction=\"minimize\")\n",
    "lgb_study.optimize(opt_func, n_trials=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107166bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_study.trials_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bdef4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "Best_trial = lgb_study.best_trial.params\n",
    "Best_trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052dacbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rf\n",
    "opt_func = partial(optimizer, X=X, y=y, model='rf')\n",
    "\n",
    "rf_study = optuna.create_study(direction=\"minimize\")\n",
    "rf_study.optimize(opt_func, n_trials=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fda78da",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_study.trials_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905f5b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "Best_trial = rf_study.best_trial.params\n",
    "Best_trial"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
